apiVersion: nebula.lyft.com/v1alpha1
executionConfig:
  EnvironmentVariables: null
  Interruptible: null
  MaxParallelism: 0
  OverwriteCache: false
  RecoveryExecution: {}
  TaskPluginImpls: null
  TaskResources:
    Limits:
      CPU: "0"
      EphemeralStorage: "0"
      GPU: "0"
      Memory: "0"
      Storage: "0"
    Requests:
      CPU: "0"
      EphemeralStorage: "0"
      GPU: "0"
      Memory: "0"
      Storage: "0"
executionId: {}
inputs:
  literals:
    data:
      scalar:
        generic: {}
    df:
      scalar:
        structuredDataset:
          metadata:
            structuredDatasetType:
              format: parquet
kind: nebulaworkflow
metadata:
  creationTimestamp: null
  labels:
    domain: domain
    execution-id: name
    project: hello
    shard-key: "6"
    workflow-name: core-nebula-basics-documented-workflow-sphinx-docstring
  name: name
  namespace: namespace
node-defaults: {}
rawOutputDataConfig: {}
securityContext: {}
spec:
  connections:
    n0:
    - end-node
    start-node:
    - n0
  edges:
    downstream:
      n0:
      - end-node
      start-node:
      - n0
    upstream:
      end-node:
      - n0
      n0:
      - start-node
  id: ::core.nebula_basics.documented_workflow.sphinx_docstring
  nodes:
    end-node:
      id: end-node
      inputBindings:
      - binding:
          promise:
            nodeId: n0
            var: o0
        var: o0
      kind: end
      resources: {}
    n0:
      id: n0
      inputBindings:
      - binding:
          promise:
            nodeId: start-node
            var: data
        var: data
      - binding:
          promise:
            nodeId: start-node
            var: df
        var: df
      kind: task
      name: add_data
      resources: {}
      task: 'resource_type:TASK name:"core.nebula_basics.documented_workflow.add_data" '
    start-node:
      id: start-node
      kind: start
      resources: {}
  outputBindings:
  - binding:
      promise:
        nodeId: n0
        var: o0
    var: o0
  outputs:
    variables:
      o0:
        type:
          structuredDatasetType:
            format: parquet
status:
  phase: 0
tasks:
  'resource_type:TASK name:"core.nebula_basics.documented_workflow.add_data" ':
    container:
      args:
      - pynebula-execute
      - --inputs
      - '{{.input}}'
      - --output-prefix
      - '{{.outputPrefix}}'
      - --raw-output-data-prefix
      - '{{.rawOutputDataPrefix}}'
      - --checkpoint-path
      - '{{.checkpointOutputPrefix}}'
      - --prev-checkpoint
      - '{{.prevCheckpointPrefix}}'
      - --resolver
      - nebulakit.core.python_auto_container.default_task_resolver
      - --
      - task-module
      - core.nebula_basics.documented_workflow
      - task-name
      - add_data
      config:
      - key: testKey1
        value: testValue1
      - key: testKey2
        value: testValue2
      - key: testKey3
        value: testValue3
      image: ghcr.io/nebulaclouds/nebulacookbook:core-8b8e1a849c9adfca88049a074b10dad278f70077
      resources: {}
    id:
      name: core.nebula_basics.documented_workflow.add_data
      resourceType: TASK
    interface:
      inputs:
        variables:
          data:
            type:
              simple: STRUCT
          df:
            type:
              structuredDatasetType:
                format: parquet
      outputs:
        variables:
          o0:
            type:
              structuredDatasetType:
                format: parquet
    metadata:
      retries: {}
      runtime:
        flavor: python
        type: NEBULA_SDK
        version: 0.32.6
    type: python-task
