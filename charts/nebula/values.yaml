--- # ---------------------------------------------------------------------
# ---------------------------------------------------------------------
# Core System settings
# This section consists of Core components of Nebula and their deployment
# settings. This includes NebulaAdmin service, Datacatalog, NebulaPropeller and
# Nebulaconsole
nebula:
  #
  # NEBULAADMIN SETTINGS
  #

  nebulaadmin:
    # -- Replicas count for Nebulaadmin deployment
    replicaCount: 1
    image:
      # -- Docker image for Nebulaadmin deployment
      repository: cr.nebula.org/nebulaclouds/nebulaadmin # NEBULAADMIN_IMAGE
      # -- Docker image tag
      tag: v1.10.6 # NEBULAADMIN_TAG
      # -- Docker image pull policy
      pullPolicy: IfNotPresent
    # -- Additional nebulaadmin container environment variables
    #
    # e.g. SendGrid's API key
    #  - name: SENDGRID_API_KEY
    #    value: "<your sendgrid api key>"
    #
    # e.g. secret environment variable (you can combine it with .additionalVolumes):
    # - name: SENDGRID_API_KEY
    #   valueFrom:
    #     secretKeyRef:
    #       name: sendgrid-secret
    #       key: api_key
    env: []
    # -- Default resources requests and limits for Nebulaadmin deployment
    resources:
      limits:
        cpu: 250m
        ephemeral-storage: 100Mi
        memory: 500Mi
      requests:
        cpu: 10m
        ephemeral-storage: 50Mi
        memory: 50Mi
    # -- Default regex string for searching configuration files
    configPath: /etc/nebula/config/*.yaml
    # -- Initial projects to create
    initialProjects:
      - nebulasnacks
      - nebulatester
      - nebulaexamples
    # -- Service settings for Nebulaadmin
    service:
      annotations:
        projectcontour.io/upstream-protocol.h2c: grpc
      type: ClusterIP
      loadBalancerSourceRanges: []
    # -- Configuration for service accounts for NebulaAdmin
    serviceAccount:
      # -- Should a service account be created for nebulaadmin
      create: true
      # -- Annotations for ServiceAccount attached to Nebulaadmin pods
      annotations: {}
      # -- ImagePullSecrets to automatically assign to the service account
      imagePullSecrets: []
    # -- Annotations for Nebulaadmin pods
    podAnnotations: {}
    # -- nodeSelector for Nebulaadmin deployment
    nodeSelector: {}
    # -- tolerations for Nebulaadmin deployment
    tolerations: []
    # -- affinity for Nebulaadmin deployment
    affinity: {}
    secrets: {}
    additionalVolumes: []
    additionalVolumeMounts: []

  #
  # NEBULASCHEDULER SETTINGS
  #

  nebulascheduler:
    image:
      # -- Docker image for Nebulascheduler deployment
      repository: cr.nebula.org/nebulaclouds/nebulascheduler # NEBULASCHEDULER_IMAGE
      # -- Docker image tag
      tag: v1.10.6 # NEBULASCHEDULER_TAG
      # -- Docker image pull policy
      pullPolicy: IfNotPresent
    # -- Default resources requests and limits for Nebulascheduler deployment
    resources:
      limits:
        cpu: 250m
        ephemeral-storage: 100Mi
        memory: 500Mi
      requests:
        cpu: 10m
        ephemeral-storage: 50Mi
        memory: 50Mi
    # -- Default regex string for searching configuration files
    configPath: /etc/nebula/config/*.yaml

    # -- Configuration for service accounts for Nebulascheduler
    serviceAccount:
      # -- Should a service account be created for Nebulascheduler
      create: true
      # -- Annotations for ServiceAccount attached to Nebulascheduler pods
      annotations: {}
      # -- ImagePullSecrets to automatically assign to the service account
      imagePullSecrets: []
    # -- Annotations for Nebulascheduler pods
    podAnnotations: {}
    # -- nodeSelector for Nebulascheduler deployment
    nodeSelector: {}
    # -- tolerations for Nebulascheduler deployment
    tolerations: []
    # -- affinity for Nebulascheduler deployment
    affinity: {}
    secrets: {}

  #
  # DATACATALOG SETTINGS
  #

  datacatalog:
    # -- Replicas count for Datacatalog deployment
    replicaCount: 1
    image:
      # -- Docker image for Datacatalog deployment
      repository: cr.nebula.org/nebulaclouds/datacatalog # DATACATALOG_IMAGE
      # -- Docker image tag
      tag: v1.10.6 # DATACATALOG_TAG
      # -- Docker image pull policy
      pullPolicy: IfNotPresent
    # -- Default resources requests and limits for Datacatalog deployment
    resources:
      limits:
        cpu: 500m
        ephemeral-storage: 100Mi
        memory: 500Mi
      requests:
        cpu: 10m
        ephemeral-storage: 50Mi
        memory: 50Mi
    # -- Default regex string for searching configuration files
    configPath: /etc/datacatalog/config/*.yaml
    # -- Service settings for Datacatalog
    service:
      annotations:
        projectcontour.io/upstream-protocol.h2c: grpc
      type: NodePort
    # -- Configuration for service accounts for Datacatalog
    serviceAccount:
      # -- Should a service account be created for Datacatalog
      create: true
      # -- Annotations for ServiceAccount attached to Datacatalog pods
      annotations: {}
      # -- ImagePullSecrets to automatically assign to the service account
      imagePullSecrets: []
    # -- Annotations for Datacatalog pods
    podAnnotations: {}
    # -- nodeSelector for Datacatalog deployment
    nodeSelector: {}
    # -- tolerations for Datacatalog deployment
    tolerations: []
    # -- affinity for Datacatalog deployment
    affinity: {}

  #
  # NEBULAPROPELLER SETTINGS
  #

  nebulapropeller:
    # -- Replicas count for Nebulapropeller deployment
    replicaCount: 1
    manager: false
    image:
      # -- Docker image for Nebulapropeller deployment
      repository: cr.nebula.org/nebulaclouds/nebulapropeller # NEBULAPROPELLER_IMAGE
      # -- Docker image tag
      tag: v1.10.6 # NEBULAPROPELLER_TAG
      # -- Docker image pull policy
      pullPolicy: IfNotPresent
    # -- Default resources requests and limits for Nebulapropeller deployment
    resources:
      limits:
        cpu: 200m
        ephemeral-storage: 100Mi
        memory: 200Mi
      requests:
        cpu: 10m
        ephemeral-storage: 50Mi
        memory: 50Mi
    cacheSizeMbs: 0
    # -- Default regex string for searching configuration files
    configPath: /etc/nebula/config/*.yaml

    # -- Configuration for service accounts for NebulaPropeller
    serviceAccount:
      # -- Should a service account be created for NebulaPropeller
      create: true
      # -- Annotations for ServiceAccount attached to NebulaPropeller pods
      annotations: {}
      # -- ImagePullSecrets to automatically assign to the service account
      imagePullSecrets: []
    # -- Annotations for Nebulapropeller pods
    podAnnotations: {}
    # -- nodeSelector for Nebulapropeller deployment
    nodeSelector: {}
    # -- tolerations for Nebulapropeller deployment
    tolerations: []
    # -- affinity for Nebulapropeller deployment
    affinity: {}

  #
  # NEBULACONSOLE SETTINGS
  #

  nebulaconsole:
    # -- Replicas count for Nebulaconsole deployment
    replicaCount: 1
    image:
      # -- Docker image for Nebulaconsole deployment
      repository: cr.nebula.org/nebulaclouds/nebulaconsole # NEBULACONSOLE_IMAGE
      # -- Docker image tag
      tag: v1.10.2 # NEBULACONSOLE_TAG
      # -- Docker image pull policy
      pullPolicy: IfNotPresent
    # -- Default resources requests and limits for Nebulaconsole deployment
    resources:
      limits:
        cpu: 500m
        memory: 275Mi
      requests:
        cpu: 10m
        memory: 250Mi
    # -- Service settings for Nebulaconsole
    service:
      annotations: {}
      type: ClusterIP
    # -- Annotations for Nebulaconsole pods
    podAnnotations: {}
    # -- nodeSelector for Nebulaconsole deployment
    nodeSelector: {}
    # -- tolerations for Nebulaconsole deployment
    tolerations: []
    # -- affinity for Nebulaconsole deployment
    affinity: {}
    ga:
      enabled: true
      tracking_id: "G-0QW4DJWJ20"

  #
  # WEBHOOK SETTINGS
  #

  webhook:
    # -- enable or disable secrets webhook
    enabled: true
    # -- Configuration for service accounts for the webhook
    serviceAccount:
      # -- Should a service account be created for the webhook
      create: true

      # -- Annotations for ServiceAccount attached to the webhook
      annotations: {}
      # -- ImagePullSecrets to automatically assign to the service account
      imagePullSecrets: []
    # -- Service settings for the webhook
    service:
      annotations:
        projectcontour.io/upstream-protocol.h2c: grpc
      type: ClusterIP

  # It will enable the re doc route in ingress
  deployRedoc: true

  # ------------------------------------------------
  #
  # COMMON SETTINGS
  #
  common:
    databaseSecret:
      # -- Specify name of K8s Secret which contains Database password. Leave it empty if you don't need this Secret
      name: ""

      # -- Specify your Secret (with sensitive data) or pseudo-manifest (without sensitive data). See https://github.com/godaddy/kubernetes-external-secrets
      secretManifest: {}
    ingress:
      # --- Ingress hostname
      host: ""
      # --- Enable or disable creating Ingress for Nebula. Relevant to disable when using e.g. Istio as ingress controller.
      enabled: true
      # --- Enable or disable HMR route to nebulaconsole. This is useful only for frontend development.
      webpackHMR: true
      # --- separateGrpcIngress puts GRPC routes into a separate ingress if true. Required for certain ingress controllers like nginx.
      separateGrpcIngress: false
      # --- Extra Ingress annotations applied only to the GRPC ingress. Only makes sense if `separateGrpcIngress` is enabled.
      separateGrpcIngressAnnotations:
        nginx.ingress.kubernetes.io/backend-protocol: "GRPC"
      # --- Ingress annotations applied to both HTTP and GRPC ingresses.
      annotations:
        nginx.ingress.kubernetes.io/app-root: /console
      # --- albSSLRedirect adds a special route for ssl redirect. Only useful in combination with the AWS LoadBalancer Controller.
      albSSLRedirect: false
      # --- TLS Settings
      tls:
        enabled: false
    nebulaNamespaceTemplate:
      # --- Enable or disable creating Nebula namespace in template. Enable when using helm as template-engine only. Disable when using `helm install ...`.
      enabled: false

  # -----------------------------------------------------
  # Core dependencies that should be configured for Nebula to work on any platform
  # Specifically 2 - Storage (s3, gcs etc), Production RDBMS - Aurora, CloudSQL etc
  # ------------------------------------------------------
  #
  # STORAGE SETTINGS
  #

  storage:
    # -- Sets the storage type. Supported values are sandbox, s3, gcs and custom.
    type: sandbox
    # -- bucketName defines the storage bucket nebula will use. Required for all types except for sandbox.
    bucketName: my-s3-bucket
    # -- settings for storage type s3
    s3:
      region: us-east-1
    # -- settings for storage type gcs
    gcs:
    # -- GCP project ID. Required for storage type gcs.
    # projectId:
    # -- GCP service account key for GSA with bucket access. Leave empty if you use workload identity.
    # serviceAccountKey: ""
    # -- Settings for storage type custom. See https://github.com/graymeta/stow for supported storage providers/settings.
    custom: {}

  # Database configuration
  db:
    datacatalog:
      database:
        port: 5432
        username: postgres
        host: postgres
        dbname: "datacatalog"
    admin:
      database:
        port: 5432
        username: postgres
        host: postgres
        dbname: "nebulaadmin"

  # --------------------------------------------------------------------
  # Specializing your deployment using configuration
  # -------------------------------------------------------------------
  #
  # CONFIGMAPS SETTINGS
  #

  configmap:
    # -- Configuration for Nebula console UI
    console:
      BASE_URL: /console
      CONFIG_DIR: /etc/nebula/config

    # -- Domains configuration for Nebula projects. This enables the specified number of domains across all projects in Nebula.
    domain:
      domains:
        - id: development
          name: development
        - id: staging
          name: staging
        - id: production
          name: production

    # -- NebulaAdmin server configuration
    adminServer:
      # Refer to the [server config](https://pkg.go.dev/github.com/lyft/nebulaadmin@v0.3.37/pkg/config#ServerConfig).
      server:
        httpPort: 8088
        grpcPort: 8089
        security:
          # -- Controls whether to serve requests over SSL/TLS.
          secure: false
          # -- Controls whether to enforce authentication. Follow the guide in https://docs.nebula.org/ on how to setup authentication.
          useAuth: false
          allowCors: true
          allowedOrigins:
            # Accepting all domains for Sandbox installation
            - "*"
          allowedHeaders:
            - "Content-Type"
            - "nebula-authorization"
      # Refer to the full [structure](https://pkg.go.dev/github.com/lyft/nebulaadmin@v0.3.37/pkg/runtime/interfaces#ApplicationConfig) for documentation.
      nebulaadmin:
        roleNameKey: "iam.amazonaws.com/role"
        profilerPort: 10254
        metricsScope: "nebula:"
        metadataStoragePrefix:
          - "metadata"
          - "admin"
        eventVersion: 2
        testing:
          host: http://nebulaadmin
      # -- Authentication configuration
      auth:
        authorizedUris:
          # This should point at your public http Uri.
          - https://localhost:30081
          # This will be used by internal services in the same namespace as nebulaadmin
          - http://nebulaadmin:80
          # This will be used by internal services in the same cluster but different namespaces
          - http://nebulaadmin.nebula.svc.cluster.local:80

        # Controls app authentication config
        appAuth:
          thirdPartyConfig:
            nebulaClient:
              clientId: nebulactl
              redirectUri: http://localhost:53593/callback
              scopes:
                - offline
                - all
        # Controls user authentication
        userAuth:
          openId:
            baseUrl: https://accounts.google.com
            scopes:
              - profile
              - openid
            clientId: 657465813211-6eog7ek7li5k7i7fvgv2921075063hpe.apps.googleusercontent.com

    # -- Datacatalog server config
    datacatalogServer:
      datacatalog:
        storage-prefix: metadata/datacatalog
        metrics-scope: datacatalog
        profiler-port: 10254
      application:
        grpcPort: 8089
        httpPort: 8080
        grpcServerReflection: true

    # -- Task default resources configuration
    # Refer to the full [structure](https://pkg.go.dev/github.com/lyft/nebulaadmin@v0.3.37/pkg/runtime/interfaces#TaskResourceConfiguration).
    task_resource_defaults:
      # -- Task default resources parameters
      task_resources:
        defaults:
          cpu: 100m
          memory: 200Mi
          storage: 5Mi
        limits:
          cpu: 2
          memory: 1Gi
          storage: 20Mi
          gpu: 1

    # -- Catalog Client configuration [structure](https://pkg.go.dev/github.com/nebulaclouds/nebulapropeller/pkg/controller/nodes/task/catalog#Config)
    # Additional advanced Catalog configuration [here](https://pkg.go.dev/github.com/lyft/nebulaplugins/go/tasks/pluginmachinery/catalog#Config)
    catalog:
      catalog-cache:
        endpoint: datacatalog:89
        type: datacatalog
        insecure: true

    # -- Copilot configuration
    copilot:
      plugins:
        k8s:
          # -- Structure documented [here](https://pkg.go.dev/github.com/lyft/nebulaplugins@v0.5.28/go/tasks/pluginmachinery/nebulak8s/config#NebulaCoPilotConfig)
          co-pilot:
            name: nebula-copilot-
            image: cr.nebula.org/nebulaclouds/nebulacopilot:v1.10.6 # NEBULACOPILOT_IMAGE
            start-timeout: 30s

    # -- Core propeller configuration
    core:
      # -- follows the structure specified [here](https://pkg.go.dev/github.com/nebulaclouds/nebulapropeller/pkg/controller/config).
      propeller:
        rawoutput-prefix: s3://my-s3-bucket/
        metadata-prefix: metadata/propeller
        workers: 4
        max-workflow-retries: 30
        workflow-reeval-duration: 30s
        downstream-eval-duration: 30s
        limit-namespace: "all"
        prof-port: 10254
        metrics-prefix: nebula
        enable-admin-launcher: true
        leader-election:
          lock-config-map:
            name: propeller-leader
            namespace: nebula
          enabled: true
          lease-duration: 15s
          renew-deadline: 10s
          retry-period: 2s
        queue:
          type: batch
          batching-interval: 2s
          batch-size: -1
          queue:
            type: maxof
            rate: 100
            capacity: 1000
            base-delay: 5s
            max-delay: 120s
          sub-queue:
            type: bucket
            rate: 10
            capacity: 100
      webhook:
        certDir: /etc/webhook/certs
        serviceName: nebula-pod-webhook
      # -- For Workflow store use configuration [here](https://pkg.go.dev/github.com/nebulaclouds/nebulapropeller/pkg/controller/workflowstore#Config)
      #

    enabled_plugins:
      # -- Tasks specific configuration [structure](https://pkg.go.dev/github.com/nebulaclouds/nebulapropeller/pkg/controller/nodes/task/config#GetConfig)
      tasks:
        # -- Plugins configuration, [structure](https://pkg.go.dev/github.com/nebulaclouds/nebulapropeller/pkg/controller/nodes/task/config#TaskPluginConfig)
        task-plugins:
          # -- [Enabled Plugins](https://pkg.go.dev/github.com/lyft/nebulaplugins/go/tasks/config#Config). Enable sagemaker*, athena if you install the backend
          # plugins
          enabled-plugins:
            - container
            - sidecar
            - k8s-array
            - agent-service
          default-for-task-types:
            container: container
            sidecar: sidecar
            container_array: k8s-array
            bigquery_query_job_task: agent-service


    # -- Kubernetes specific Nebula configuration
    k8s:
      plugins:
        # -- Configuration section for all K8s specific plugins [Configuration structure](https://pkg.go.dev/github.com/lyft/nebulaplugins/go/tasks/pluginmachinery/nebulak8s/config)
        k8s:
          #  DEFAULT_ENV_VAR: VALUE
          default-cpus: 100m
          default-env-vars:
            - NEBULA_AWS_ENDPOINT: "http://minio.nebula:9000"
            - NEBULA_AWS_ACCESS_KEY_ID: minio
            - NEBULA_AWS_SECRET_ACCESS_KEY: miniostorage
          default-memory: 200Mi
        agent-service:
          defaultAgent:
            endpoint: dns:///nebulaagent.nebula.svc.cluster.local:8000
            insecure: true
          supportedTaskTypes:
            - bigquery_query_job_task

    # -- Logger configuration
    logger:
      logger:
        show-source: true
        level: 5

    remoteData:
      remoteData:
        region: "us-east-1"
        scheme: "local"
        signedUrls:
          durationMinutes: 3

    # -- Resource manager configuration
    resource_manager:
      # -- resource manager configuration
      propeller:
        resourcemanager:
          type: noop
          redis: null

    # -- Section that configures how the Task logs are displayed on the UI. This has to be changed based on your actual logging provider.
    # Refer to [structure](https://pkg.go.dev/github.com/lyft/nebulaplugins/go/tasks/logs#LogConfig) to understand how to configure various
    # logging engines
    task_logs:
      plugins:
        logs:
          kubernetes-enabled: true
          kubernetes-template-uri: 'http://localhost:30082/#/log/{{ "{{" }} .namespace {{ "}}" }}/{{ "{{" }} .podName {{ "}}" }}/pod?namespace={{ "{{" }} .namespace {{ "}}" }}'
          # -- One option is to enable cloudwatch logging for EKS, update the region and log group accordingly
          cloudwatch-enabled: false

  # ----------------------------------------------------------------
  # Optional Modules
  # Nebula built extensions that enable various additional features in Nebula.
  # All these features are optional, but are critical to run certain features
  # ------------------------------------------------------------------------

  # -- **Optional Component**
  # Nebula uses a cloud hosted Cron scheduler to run workflows on a schedule. The following module is optional. Without,
  # this module, you will not have scheduled launchplans / workflows.
  # Docs: https://docs.nebula.org/en/latest/howto/enable_and_use_schedules.html#setting-up-scheduled-workflows
  workflow_scheduler:
    enabled: true
    type: native

  # -- **Optional Component**
  # Workflow notifications module is an optional dependency. Nebula uses cloud native pub-sub systems to notify users of
  # various events in their workflows
  workflow_notifications:
    enabled: false
    config: {}

  # -- Configuration for the Cluster resource manager component. This is an optional component, that enables automatic
  # cluster configuration. This is useful to set default quotas, manage namespaces etc that map to a project/domain
  cluster_resource_manager:
    # -- Enables the Cluster resource manager component
    enabled: true
    # -- Service account name to run with
    service_account_name: nebulaadmin
    config:
      # -- ClusterResource parameters
      # Refer to the [structure](https://pkg.go.dev/github.com/lyft/nebulaadmin@v0.3.37/pkg/runtime/interfaces#ClusterResourceConfig) to customize.
      cluster_resources:
        refreshInterval: 5m
        templatePath: "/etc/nebula/clusterresource/templates"
        # -- Starts the cluster resource manager in standalone mode with requisite auth credentials to call nebulaadmin service endpoints
        standaloneDeployment: false
        customData:
          - production:
              - projectQuotaCpu:
                  value: "5"
              - projectQuotaMemory:
                  value: "4000Mi"
          - staging:
              - projectQuotaCpu:
                  value: "2"
              - projectQuotaMemory:
                  value: "3000Mi"
          - development:
              - projectQuotaCpu:
                  value: "4"
              - projectQuotaMemory:
                  value: "3000Mi"
        refresh: 5m

    # -- Resource templates that should be applied
    templates:
      # -- Template for namespaces resources
      - key: aa_namespace
        value: |
          apiVersion: v1
          kind: Namespace
          metadata:
            name: {{ namespace }}
          spec:
            finalizers:
            - kubernetes
      - key: ab_project_resource_quota
        value: |
          apiVersion: v1
          kind: ResourceQuota
          metadata:
            name: project-quota
            namespace: {{ namespace }}
          spec:
            hard:
              limits.cpu: {{ projectQuotaCpu }}
              limits.memory: {{ projectQuotaMemory }}

# ----------------------------------------------
# Sandbox Configuration
# Sandbox allows to run nebula without any cloud dependencies and can be run even locally on your laptop.
# This is achieved by replacing cloud service dependencies by k8s local alternatives. These may not be ideal
# for a high performance setup, but are great to try out nebula
# -----------------------------------------------
#
# REDIS SETTINGS
#

redis:
  # --- enable or disable Redis Statefulset installation
  enabled: false

#
# POSTGRES SETTINGS
#

postgres:
  # --- enable or disable Postgres deployment installation
  enabled: true
  # -- Replicas count for Postgres deployment
  replicaCount: 1
  image:
    # -- Docker image for Postgres deployment
    repository: ecr.nebula.org/ubuntu/postgres
    # -- Docker image tag
    tag: 13-21.04_beta
    # -- Docker image pull policy
    pullPolicy: IfNotPresent
  # -- Default resources requests and limits for Postgres deployment
  resources:
    requests:
      cpu: 10m
      memory: 128Mi
    limits:
      cpu: 1000m
      memory: 512Mi
  # -- Service settings for Postgres
  service:
    annotations: {}
    type: NodePort
  # -- Annotations for Postgres pods
  podAnnotations: {}
  # -- nodeSelector for Postgres deployment
  nodeSelector: {}
  # -- tolerations for Postgres deployment
  tolerations: []
  # -- affinity for Postgres deployment
  affinity: {}

#
# MINIO SETTINGS
#

minio:
  # --- enable or disable Minio deployment installation
  enabled: true
  # -- Replicas count for Minio deployment
  replicaCount: 1
  image:
    # -- Docker image for Minio deployment
    repository: ecr.nebula.org/bitnami/minio
    # -- Docker image tag
    tag: 2021.10.13-debian-10-r0
    # -- Docker image pull policy
    pullPolicy: IfNotPresent
  # -- Default resources requests and limits for Minio deployment
  resources:
    # -- Requests are the minimum set of resources needed for this pod
    requests:
      cpu: 10m
      memory: 128Mi
    # -- Limits are the maximum set of resources needed for this pod
    limits:
      cpu: 200m
      memory: 512Mi
  # -- Service settings for Minio
  service:
    annotations: {}
    type: NodePort
  # -- Annotations for Minio pods
  podAnnotations: {}
  # -- nodeSelector for Minio deployment
  nodeSelector: {}
  # -- tolerations for Minio deployment
  tolerations: []
  # -- affinity for Minio deployment
  affinity: {}

redoc:
  # --- enable or disable Minio deployment installation
  enabled: true
  # -- Replicas count for Minio deployment
  replicaCount: 1
  image:
    # -- Docker image for Minio deployment
    repository: docker.io/redocly/redoc
    # -- Docker image tag
    tag: latest
    # -- Docker image pull policy
    pullPolicy: IfNotPresent
  # -- Default resources requests and limits for Minio deployment
  resources:
    # -- Requests are the minimum set of resources needed for this pod
    requests:
      cpu: 10m
      memory: 128Mi
    # -- Limits are the maximum set of resources needed for this pod
    limits:
      cpu: 200m
      memory: 512Mi
  # -- Service settings for Minio
  service:
    type: ClusterIP
  # -- Annotations for Minio pods
  podAnnotations: {}
  # -- nodeSelector for Minio deployment
  nodeSelector: {}
  # -- tolerations for Minio deployment
  tolerations: []
  # -- affinity for Minio deployment
  affinity: {}

#
# CONTOUR SETTINGS
#

contour:
  # --- enable or disable Contour deployment installation
  enabled: true
  # -- Replicas count for Contour deployment
  replicaCount: 1
  contour:
    # -- Default resources requests and limits for Contour
    resources:
      # -- Requests are the minimum set of resources needed for this pod
      requests:
        cpu: 10m
        memory: 50Mi
      # -- Limits are the maximum set of resources needed for this pod
      limits:
        cpu: 100m
        memory: 100Mi
  envoy:
    service:
      type: NodePort
      ports:
        http: 80
      nodePorts:
        http: 30081
    # -- Default resources requests and limits for Envoy
    resources:
      # -- Requests are the minimum set of resources needed for this pod
      requests:
        cpu: 10m
        memory: 50Mi
      # -- Limits are the maximum set of resources needed for this pod
      limits:
        cpu: 100m
        memory: 100Mi
  # -- Annotations for ServiceAccount attached to Contour pods
  serviceAccountAnnotations: {}
  # -- Annotations for Contour pods
  podAnnotations: {}
  # -- nodeSelector for Contour deployment
  nodeSelector: {}
  # -- tolerations for Contour deployment
  tolerations: []
  # -- affinity for Contour deployment
  affinity: {}

#
# KUBERNETES DASHBOARD
#
kubernetes-dashboard:
  enabled: true
  extraArgs:
    - --enable-skip-login
    - --enable-insecure-login
    - --disable-settings-authorizer
  protocolHttp: true
  rbac:
    clusterReadOnlyRole: true
  service:
    type: NodePort
    externalPort: 30082
    nodePort: 30082

# -- Optional: Spark Plugin using the Spark Operator
sparkoperator:
  # --- enable or disable Sparkoperator deployment installation
  enabled: false

# -- Optional: Dask Plugin using the Dask Operator
daskoperator:
  # --- enable or disable the dask operator deployment installation
  enabled: false

nebulaagent:
  enabled: true
