
nebulaadmin:
  serviceMonitor:
    enabled: false
  service:
    annotations:
      projectcontour.io/upstream-protocol.h2c: grpc
    type: ClusterIP
    loadBalancerSourceRanges: []

datacatalog:
  service:
    annotations:
      projectcontour.io/upstream-protocol.h2c: grpc
    type: NodePort

nebulaconsole:
  ga:
    enabled: true
    tracking_id: "G-0QW4DJWJ20"

deployRedoc: true

common:
  databaseSecret:
    # -- Specify name of K8s Secret which contains Database password. Leave it empty if you don't need this Secret
    name: ""

    # -- Specify your Secret (with sensitive data) or pseudo-manifest (without sensitive data). See https://github.com/godaddy/kubernetes-external-secrets
    secretManifest: {}
  ingress:
    host: ""
    webpackHMR: true

db:
  datacatalog:
    database:
      port: 5432
      username: postgres
      host: postgres
      dbname: "datacatalog"
  admin:
    database:
      port: 5432
      username: postgres
      host: postgres
      dbname: "nebulaadmin"

configmap:
  console:
    CONFIG_DIR: /etc/nebula/config

  # -- Task default resources configuration
  # Refer to the full [structure](https://pkg.go.dev/github.com/lyft/nebulaadmin@v0.3.37/pkg/runtime/interfaces#TaskResourceConfiguration).
  task_resource_defaults:
    # -- Task default resources parameters
    task_resources:
      defaults:
        cpu: 500m
        memory: 1Gi
      limits:
        cpu: 2
        memory: 4Gi
        gpu: 5


  # -- Kubernetes specific Nebula configuration
  k8s:
    plugins:
      # -- Configuration section for all K8s specific plugins [Configuration structure](https://pkg.go.dev/github.com/lyft/nebulaplugins/go/tasks/pluginmachinery/nebulak8s/config)
      k8s:
        #  DEFAULT_ENV_VAR: VALUE
        default-cpus: 100m
        default-env-vars:
          - NEBULA_AWS_ENDPOINT: "http://minio.nebula.svc.cluster.local:9000"
          - NEBULA_AWS_ACCESS_KEY_ID: minio
          - NEBULA_AWS_SECRET_ACCESS_KEY: miniostorage
        default-memory: 200Mi

  remoteData:
    remoteData:
      region: "us-east-1"
      scheme: "local"
      signedUrls:
        durationMinutes: 3

  # -- Resource manager configuration
  resource_manager:
    # -- resource manager configuration
    propeller:
      resourcemanager:
        type: noop
        redis: null

  task_logs:
    plugins:
      logs:
        kubernetes-enabled: true
        kubernetes-template-uri: 'http://localhost:30082/#/log/{{ "{{" }} .namespace {{ "}}" }}/{{ "{{" }} .podName {{ "}}" }}/pod?namespace={{ "{{" }} .namespace {{ "}}" }}'
        # -- One option is to enable cloudwatch logging for EKS, update the region and log group accordingly
        cloudwatch-enabled: false

# -- # Nebula uses a cloud hosted Cron scheduler to run workflows on a schedule. The following module is optional. Without,
# this module, you will not have scheduled launchplans/workflows.
# by default aws use nebula native scheduler i.e nebulascheduler
# To use aws native scheduler please override the eks values
workflow_scheduler:
  enabled: true
  type: native

workflow_notifications:
  enabled: false
  config: {}

redis:
  # --- enable or disable Redis Statefulset installation
  enabled: false

# -- Configuration for the Cluster resource manager component. This is an optional component, that enables automatic
# cluster configuration. This is useful to set default quotas, manage namespaces etc that map to a project/domain
cluster_resource_manager:
  # -- Enables the Cluster resource manager component
  enabled: true
  standaloneDeployment: false
  # -- Service account name to run with
  service_account_name: nebulaadmin
  # -- Annotations for ClusterResource pods
  podAnnotations: {}
  # -- Configmap for ClusterResource parameters
  config:
    # -- ClusterResource parameters
    # Refer to the [structure](https://pkg.go.dev/github.com/lyft/nebulaadmin@v0.3.37/pkg/runtime/interfaces#ClusterResourceConfig) to customize.
    cluster_resources:
      # -- How frequently to run the sync process
      refreshInterval: 5m
      templatePath: "/etc/nebula/clusterresource/templates"
      # -- Starts the cluster resource manager in standalone mode with requisite auth credentials to call nebulaadmin service endpoints
      standaloneDeployment: false
      customData:
        - production:
            - projectQuotaCpu:
                value: "8"
            - projectQuotaMemory:
                value: "16Gi"
        - staging:
            - projectQuotaCpu:
                value: "8"
            - projectQuotaMemory:
                value: "16Gi"
        - development:
            - projectQuotaCpu:
                value: "8"
            - projectQuotaMemory:
                value: "16Gi"

  # -- Resource templates that should be applied
  templates:
    # -- Template for namespaces resources
    - key: aa_namespace
      value: |
        apiVersion: v1
        kind: Namespace
        metadata:
          name: {{ namespace }}
        spec:
          finalizers:
          - kubernetes

    - key: ab_project_resource_quota
      value: |
        apiVersion: v1
        kind: ResourceQuota
        metadata:
          name: project-quota
          namespace: {{ namespace }}
        spec:
          hard:
            limits.cpu: {{ projectQuotaCpu }}
            limits.memory: {{ projectQuotaMemory }}
